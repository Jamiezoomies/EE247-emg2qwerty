2025-02-25 07:58:23.833771: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1740470303.869050    9643 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1740470303.881050    9643 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
Global seed set to 1501
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: /content/drive/MyDrive/projects/emg2qwerty-main/logs/2025-02-25/07-58-17/job0_trainer.devices=1,user=single_user/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.
  if not hasattr(numpy, tp_name):
/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  "lr_options": generate_power_seq(LEARNING_RATE_CIFAR, 11),
/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask("01, 02, 11"),
/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  self.nce_loss = AmdimNCELoss(tclip)
/usr/local/lib/python3.11/dist-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html
  return _target_(*args, **kwargs)

  | Name     | Type       | Params
----------------------------------------
0 | model    | Sequential | 5.3 M 
1 | ctc_loss | CTCLoss    | 0     
2 | metrics  | ModuleDict | 0     
----------------------------------------
5.3 M     Trainable params
0         Non-trainable params
5.3 M     Total params
21.173    Total estimated model params size (MB)
/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
Epoch 0, global step 120: 'val/CER' reached 1358.08594 (best 1358.08594), saving model to '/content/drive/MyDrive/projects/emg2qwerty-main/logs/2025-02-25/07-58-17/job0_trainer.devices=1,user=single_user/checkpoints/epoch=0-step=120.ckpt' as top 1
Epoch 1, global step 240: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/content/drive/MyDrive/projects/emg2qwerty-main/logs/2025-02-25/07-58-17/job0_trainer.devices=1,user=single_user/checkpoints/epoch=1-step=240.ckpt' as top 1
Epoch 2, global step 360: 'val/CER' was not in top 1
Epoch 3, global step 480: 'val/CER' was not in top 1
Epoch 4, global step 600: 'val/CER' was not in top 1
Epoch 5, global step 720: 'val/CER' was not in top 1
Epoch 6, global step 840: 'val/CER' was not in top 1
Epoch 7, global step 960: 'val/CER' was not in top 1
Epoch 8, global step 1080: 'val/CER' was not in top 1
Epoch 9, global step 1200: 'val/CER' reached 99.86708 (best 99.86708), saving model to '/content/drive/MyDrive/projects/emg2qwerty-main/logs/2025-02-25/07-58-17/job0_trainer.devices=1,user=single_user/checkpoints/epoch=9-step=1200.ckpt' as top 1
Epoch 10, global step 1320: 'val/CER' reached 96.14532 (best 96.14532), saving model to '/content/drive/MyDrive/projects/emg2qwerty-main/logs/2025-02-25/07-58-17/job0_trainer.devices=1,user=single_user/checkpoints/epoch=10-step=1320.ckpt' as top 1
Epoch 11, global step 1440: 'val/CER' reached 89.18919 (best 89.18919), saving model to '/content/drive/MyDrive/projects/emg2qwerty-main/logs/2025-02-25/07-58-17/job0_trainer.devices=1,user=single_user/checkpoints/epoch=11-step=1440.ckpt' as top 1
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py", line 645, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py", line 1098, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^Exception in thread Thread-4 (_pin_memory_loop)^:
^^
Traceback (most recent call last):
  File "/usr/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py", line 1177, in _run_stage
    self._run_train()
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py", line 1200, in _run_train
    self.fit_loop.run()
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
      File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
self.run()    
self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/usr/lib/python3.11/threading.py", line 982, in run
        self._target(*self._args, **self._kwargs) 
     File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py", line 54, in _pin_memory_loop
           do_one_step()  
   ^  File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py", line 31, in do_one_step
^^^^    ^^r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)^^
^^^^  ^^  ^^  ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py", line 199, in run
^^    ^^self.advance(*args, **kwargs)
^^  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 188, in advance
^^^    ^^batch = next(data_fetcher)
^^ ^^  ^^  ^^  ^^  ^^  ^^ ^^
^^  File "/usr/lib/python3.11/multiprocessing/queues.py", line 122, in get
^    return _ForkingPickler.loads(res)^^
 ^^  ^^  ^^  ^^  ^^  ^^^
^^  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py", line 184, in __next__
^    return self.fetching_function()^^
 ^^  ^^  ^^  ^^  ^^  ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
^^^    ^^fd = df.detach()
^^ ^^  ^^  ^^  ^
    File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py", line 265, in fetching_function
^^    ^^self._fetch_next_batch(self.dataloader_iter)
^^  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py", line 280, in _fetch_next_batch
^^    ^^batch = next(iterator)
^
   File "/usr/lib/python3.11/multiprocessing/resource_sharer.py", line 57, in detach
     with _resource_sharer.get_connection(self._id) as conn:  
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/supporters.py", line 568, in __next__
^^^^^    ^^return self.request_next_batch(self.loader_iters)
^^ ^^  ^^  ^^  ^^  ^^  ^^^^^^^^^^^^^^^^
^^  File "/usr/lib/python3.11/multiprocessing/resource_sharer.py", line 86, in get_connection
^^^^    ^^c = Client(address, authkey=process.current_process().authkey)
^^ ^^  ^^  ^^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/supporters.py", line 580, in request_next_batch
^^    ^^return apply_to_collection(loader_iters, Iterator, next)
^^ ^^  ^^  ^^  ^^  ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^  File "/usr/lib/python3.11/multiprocessing/connection.py", line 519, in Client
^    c = SocketClient(address)^^
 ^^  ^^  ^^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/apply_func.py", line 65, in apply_to_collection
^    return function(data, *args, **kwargs)^^
 ^^  ^^  ^
    File "/usr/lib/python3.11/multiprocessing/connection.py", line 647, in SocketClient
        s.connect(address)
^^FileNotFoundError^^: [Errno 2] No such file or directory^^
^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py", line 1329, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py", line 1285, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py", line 1133, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/queue.py", line 180, in get
    self.not_empty.wait(remaining)
  File "/usr/lib/python3.11/threading.py", line 331, in wait
    gotit = waiter.acquire(True, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/usr/local/lib/python3.11/dist-packages/submitit/core/_submit.py", line 11, in <module>
    submitit_main()
  File "/usr/local/lib/python3.11/dist-packages/submitit/core/submission.py", line 76, in submitit_main
    process_job(args.folder)
  File "/usr/local/lib/python3.11/dist-packages/submitit/core/submission.py", line 55, in process_job
    result = delayed.result()
             ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/submitit/core/utils.py", line 137, in result
    self._result = self.function(*self.args, **self.kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/hydra_plugins/hydra_submitit_launcher/submitit_launcher.py", line 71, in __call__
    return run_job(
           ^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/drive/MyDrive/projects/emg2qwerty-main/emg2qwerty/train.py", line 107, in main
    trainer.fit(module, datamodule, ckpt_path=resume_from_checkpoint)
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py", line 603, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py", line 48, in _call_and_handle_interrupt
    rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
  File "/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/rank_zero.py", line 42, in wrapped_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/rank_zero.py", line 79, in rank_zero_warn
    _warn(message, stacklevel=stacklevel, **kwargs)
  File "/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/rank_zero.py", line 73, in _warn
    warnings.warn(message, stacklevel=stacklevel, **kwargs)
  File "/usr/lib/python3.11/warnings.py", line 113, in _showwarnmsg
    _showwarnmsg_impl(msg)
  File "/usr/lib/python3.11/warnings.py", line 28, in _showwarnmsg_impl
    text = _formatwarnmsg(msg)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/warnings.py", line 129, in _formatwarnmsg
    return _formatwarnmsg_impl(msg)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/warnings.py", line 42, in _formatwarnmsg_impl
    line = linecache.getline(msg.filename, msg.lineno)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/linecache.py", line 30, in getline
    lines = getlines(filename, module_globals)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/linecache.py", line 46, in getlines
    return updatecache(filename, module_globals)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/tokenize.py", line 398, in open
    encoding, lines = detect_encoding(buffer.readline)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/tokenize.py", line 367, in detect_encoding
    first = read_or_stop()
            ^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/tokenize.py", line 325, in read_or_stop
    return readline()
           ^^^^^^^^^^
KeyboardInterrupt
